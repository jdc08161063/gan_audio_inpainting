{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "\n",
    "from gantools import data\n",
    "from gantools import utils\n",
    "from gantools import plot\n",
    "from gantools.model import WGAN, InpaintingGAN\n",
    "from gantools.data.Dataset import Dataset\n",
    "from gantools.gansystem import GANsystem\n",
    "from gantools.data import fmap\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters for the WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_path = '../saved_results'\n",
    "\n",
    "name = 'maestro_160_64_multiple_dis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gantools import blocks\n",
    "bn = False\n",
    "signal_split = [160, 64, 160]\n",
    "md = 32\n",
    "\n",
    "params_discriminator = dict()\n",
    "params_discriminator['stride'] = [2,2,2,2,2]\n",
    "params_discriminator['nfilter'] = [md, 2*md, 4*md, 8*md, 16*md]\n",
    "params_discriminator['shape'] = [[5, 5], [5, 5], [5, 5], [5, 5], [5, 5]]\n",
    "params_discriminator['batch_norm'] = [bn, bn, bn, bn, bn]\n",
    "params_discriminator['full'] = []\n",
    "params_discriminator['minibatch_reg'] = False\n",
    "params_discriminator['summary'] = True\n",
    "params_discriminator['data_size'] = 2\n",
    "params_discriminator['apply_phaseshuffle'] = True\n",
    "params_discriminator['spectral_norm'] = True\n",
    "params_discriminator['activation'] = blocks.lrelu\n",
    "\n",
    "params_generator = dict()\n",
    "params_generator['stride'] = [2, 2, 2, 2, 2]\n",
    "params_generator['latent_dim'] = 100\n",
    "params_generator['nfilter'] = [8*md, 4*md, 2*md, md, 1]\n",
    "params_generator['shape'] = [[5, 5], [5, 5], [5, 5], [5, 5], [5, 5]]\n",
    "params_generator['batch_norm'] = [bn, bn, bn, bn]\n",
    "params_generator['full'] = [256*md]\n",
    "params_generator['summary'] = True\n",
    "params_generator['non_lin'] = tf.nn.tanh\n",
    "params_generator['activation'] = tf.nn.relu\n",
    "params_generator['data_size'] = 2\n",
    "params_generator['spectral_norm'] = True \n",
    "params_generator['in_conv_shape'] =[8, 2]\n",
    "params_generator['borders'] = dict()\n",
    "params_generator['borders']['nfilter'] = [md, 2*md, md, md/2]\n",
    "params_generator['borders']['batch_norm'] = [bn, bn, bn, bn]\n",
    "params_generator['borders']['shape'] = [[5, 5],[5, 5],[5, 5],[5, 5]]\n",
    "params_generator['borders']['stride'] = [2, 2, 3, 4]\n",
    "params_generator['borders']['data_size'] = 2\n",
    "# This does not work because of flipping, border 2 need to be flipped tf.reverse(l, axis=[1]), ask Nathanael \n",
    "params_generator['borders']['width_full'] = None \n",
    "params_generator['borders']['activation'] = tf.nn.relu\n",
    "\n",
    "\n",
    "# Optimization parameters inspired from 'Self-Attention Generative Adversarial Networks'\n",
    "# - Spectral normalization GEN DISC\n",
    "# - Batch norm GEN\n",
    "# - TTUR ('GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium')\n",
    "# - ADAM  beta1=0 beta2=0.9, disc lr 0.0004, gen lr 0.0001\n",
    "# - Hinge loss\n",
    "# Parameters are similar to the ones in those papers...\n",
    "# - 'PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION'\n",
    "# - 'LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS'\n",
    "# - 'CGANS WITH PROJECTION DISCRIMINATOR'\n",
    "\n",
    "params_optimization = dict()\n",
    "params_optimization['batch_size'] = 64*2\n",
    "params_optimization['epoch'] = 600\n",
    "params_optimization['n_critic'] = 5\n",
    "params_optimization['generator'] = dict()\n",
    "params_optimization['generator']['optimizer'] = 'adam'\n",
    "params_optimization['generator']['kwargs'] = {'beta1':0.5, 'beta2':0.9}\n",
    "params_optimization['generator']['learning_rate'] = 1e-4\n",
    "params_optimization['discriminator'] = dict()\n",
    "params_optimization['discriminator']['optimizer'] = 'adam'\n",
    "params_optimization['discriminator']['kwargs'] = {'beta1':0.5, 'beta2':0.9}\n",
    "params_optimization['discriminator']['learning_rate'] = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "# all parameters\n",
    "params = dict()\n",
    "params['net'] = dict() # All the parameters for the model\n",
    "params['net']['generator'] = params_generator\n",
    "params['net']['discriminator'] = params_discriminator\n",
    "params['net']['prior_distribution'] = 'gaussian'\n",
    "params['net']['shape'] = [256, 128*3, 1] # Shape of the image\n",
    "params['net']['inpainting']=dict()\n",
    "params['net']['inpainting']['split']=signal_split\n",
    "params['net']['gamma_gp'] = 10 # Gradient penalty\n",
    "params['net']['fs'] = 16000//downscale\n",
    "params['net']['loss_type'] ='wasserstein'\n",
    "\n",
    "params['optimization'] = params_optimization\n",
    "params['summary_every'] = 250 # Tensorboard summaries every ** iterations\n",
    "params['print_every'] = 50 # Console summaries every ** iterations\n",
    "params['save_every'] = 1000 # Save the model every ** iterations\n",
    "params['summary_dir'] = os.path.join(global_path, name +'_summary/')\n",
    "params['save_dir'] = os.path.join(global_path, name + '_checkpoints/')\n",
    "params['Nstats'] = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume, params = utils.test_resume(True, params)\n",
    "# If a model is reloaded and some parameters have to be changed, then it should be done here.\n",
    "# For example, setting the number of epoch to 5 would be:\n",
    "# params['optimization']['epoch'] = 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gantools.model import MultipleDiscrimnatorInpaintingGAN\n",
    "\n",
    "wgan = GANsystem(MultipleDiscrimnatorInpaintingGAN, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "        'train/window': tf.io.FixedLenFeature((), tf.string)}\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    spectrogram = tf.reshape(tf.decode_raw(example['train/window'], tf.float32), [256, 384])\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(\"../data/yiruma_train_inpainting_w384_h32_27261.tfrecords\")\n",
    "dataset = dataset.shuffle(buffer_size=10000)\n",
    "dataset = dataset.repeat(num_epochs)\n",
    "dataset = dataset.map(map_func=read_tfrecord)#, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.batch(batch_size=128)\n",
    "dataset = dataset.prefetch(buffer_size=1) # this should be the last transformation\n",
    "dataset.N = 2837745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 64\n",
    "nlatent = 100\n",
    "\n",
    "def clip_dist2(nsamples, nlatent, m=2.5):\n",
    "    shape = [nsamples, nlatent]\n",
    "    z = np.random.randn(*shape)\n",
    "    support = np.logical_or(z<-m, z>m)\n",
    "    while np.sum(support):\n",
    "        z[support] = np.random.randn(*shape)[support]\n",
    "        support = np.logical_or(z<-m, z>m)\n",
    "    return z\n",
    "\n",
    "d2 = clip_dist2(nsamples, nlatent)\n",
    "np.max(d2), np.min(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new samples\n",
    "To have meaningful statistics, be sure to generate enough samples\n",
    "* 2000 : 32 x 32\n",
    "* 500 : 64 x 64\n",
    "* 200 : 128 x 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "real_signals = tf.Session().run(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64*2 # Number of samples\n",
    "#real_signals = dataset.get_samples(N=N)\n",
    "border1 = real_signals[:, :, :signal_split[0]]\n",
    "border2 = real_signals[:, :, -signal_split[2]:]\n",
    "borders = np.stack([border1, border2], axis=3)\n",
    "gen_sample = np.squeeze(wgan.generate(N=N, borders=borders[:64], z=d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(gen_sample,nx=4,ny=4);\n",
    "plt.title(\"Inpainted samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(real_signals,nx=4,ny=4);\n",
    "plt.title(\"Original samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plot.draw_images(real_signals[:64]-gen_sample,nx=4,ny=4);\n",
    "plt.title(\"Diffs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Phase recovery\n",
    "\n",
    "from data.ourLTFATStft import LTFATStft\n",
    "import ltfatpy\n",
    "from phase_recovery.numba_pghi import pghi\n",
    "from data.modGabPhaseGrad import modgabphasegrad\n",
    "ltfatpy.gabphasegrad = modgabphasegrad # The original function is not implemented for one sided stfts on ltfatpy\n",
    "\n",
    "\n",
    "generated_signals = np.exp(5*(gen_sample-1)) # Undo preprocessing\n",
    "generated_signals = np.concatenate([generated_signals, np.zeros_like(gen_sample)[:, 0:1, :]], axis=1) #Fill last column of freqs with zeros\n",
    "\n",
    "fft_hop_size = 128 # Change the fft params if the dataset was generated with others\n",
    "fft_window_length = 512\n",
    "L = 16384*3\n",
    "clipBelow = -10\n",
    "\n",
    "anStftWrapper = LTFATStft()\n",
    "\n",
    "# Compute Tgrad and Fgrad from the generated spectrograms\n",
    "tgrads = np.zeros_like(generated_signals)\n",
    "fgrads = np.zeros_like(generated_signals)\n",
    "gs = {'name': 'gauss', 'M': fft_window_length}\n",
    "for index, magSpectrogram in enumerate(generated_signals):\n",
    "    tgrads[index], fgrads[index] = ltfatpy.gabphasegrad('abs', magSpectrogram, gs, fft_hop_size)\n",
    "\n",
    "reconstructed_audios = np.zeros([len(generated_signals), L])\n",
    "for index, magSpectrogram in enumerate(generated_signals):\n",
    "    logMagSpectrogram = np.log(magSpectrogram.astype(np.float64))\n",
    "    phase = pghi(logMagSpectrogram, tgrads[index], fgrads[index], fft_hop_size, fft_window_length, L, tol=10)\n",
    "    reconstructed_audios[index] = anStftWrapper.reconstructSignalFromLoggedSpectogram(logMagSpectrogram, phase, windowLength=fft_window_length, hopSize=fft_hop_size)\n",
    "\n",
    "print(\"reconstructed audios!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio\n",
    "\n",
    "for generated_audio_signal in reconstructed_audios:\n",
    "    display(Audio(generated_audio_signal, rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_audio = np.array([])\n",
    "for generated_audio_signal in reconstructed_audios:\n",
    "    complete_audio = np.append(complete_audio, np.append(generated_audio_signal, np.zeros(6000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(complete_audio, rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "librosa.output.write_wav('valid_160_64_inpainting_130k.wav', complete_audio, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(generated_audio_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_signals = ((real_signals-1)*5)\n",
    "gen_sample = ((gen_sample-1)*5)\n",
    "\n",
    "print(real_signals.max())\n",
    "print(real_signals.min())\n",
    "print(real_signals.mean())\n",
    "\n",
    "print(gen_sample.max())\n",
    "print(gen_sample.min())\n",
    "print(gen_sample.mean())\n",
    "import scipy.io\n",
    "\n",
    "scipy.io.savemat('test_valid_160_64_inpainting_130k.mat', {\"original\": real_signals, \"inpainted\": gen_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few fake samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
